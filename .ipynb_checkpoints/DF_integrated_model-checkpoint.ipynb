{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e0abce",
   "metadata": {},
   "source": [
    "# Section 1 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cd53abf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required libraries imported\n"
     ]
    }
   ],
   "source": [
    "## Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "from pulp import LpProblem, LpVariable, LpMinimize, lpSum, LpStatus\n",
    "import time \n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.random import set_seed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import ast\n",
    "\n",
    "print('Required libraries imported')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083509b3",
   "metadata": {},
   "source": [
    "# Section 2 - Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f40b0bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succuefully read: Generation_stack.xlsx\n",
      "Succuefully read: demand.csv\n",
      "Succuefully read: market_rate.xlsx\n",
      "Succuefully read: RE.xlsx\n",
      "Succuefully read: tariff.csv\n",
      "Succuefully read: input_parameters.csv\n"
     ]
    }
   ],
   "source": [
    "# read input data\n",
    "INPUT_PATH = 'D:/MpEnsystems/SE4ALL DF 2024 - 2025/DF model/input files for model/input data/'\n",
    "OUTPUT_PATH = 'D:/MpEnsystems/SE4ALL DF 2024 - 2025/DF model/input files for model/output/'\n",
    "path_for_meter_data = 'D:/MpEnsystems/SE4ALL DF 2024 - 2025/DF model/input files for model/input data/meter data/'\n",
    "\n",
    "\n",
    "ppa =pd.read_excel(INPUT_PATH + 'Generation_stack.xlsx') # PPA data of thermal plants (Capacity, ramping limts, technical min, variable cost)\n",
    "print('Succuefully read: Generation_stack.xlsx')\n",
    "projected_demand = pd.read_csv(INPUT_PATH + 'demand.csv') # Discom hourly demand in MW \n",
    "print('Succuefully read: demand.csv')\n",
    "market_price = pd.read_excel(INPUT_PATH+'market_rate.xlsx') # Power market RTM prices for last year\n",
    "print('Succuefully read: market_rate.xlsx')\n",
    "re = pd.read_excel(INPUT_PATH +'RE.xlsx') \n",
    "print('Succuefully read: RE.xlsx')\n",
    "tariff = pd.read_csv(INPUT_PATH +'tariff.csv') # cluster wise hourly tariff\n",
    "print('Succuefully read: tariff.csv')\n",
    "input_parameters = pd.read_csv(INPUT_PATH +'input_parameters.csv') # User defined parameters\n",
    "print('Succuefully read: input_parameters.csv')\n",
    "\n",
    "flex =ast.literal_eval(input_parameters[input_parameters['Parameter']=='flexibility']['Value'].values[0])\n",
    "base_incenitve_DF =float(input_parameters[input_parameters['Parameter']=='base_incenitve_DF']['Value'].values[0])\n",
    "base_incenitve_DR = float(input_parameters[input_parameters['Parameter']=='base_incenitve_DR']['Value'].values[0])\n",
    "DR_lambda = float(input_parameters[input_parameters['Parameter']=='DR_lambda']['Value'].values[0])\n",
    "DF_lambda = float(input_parameters[input_parameters['Parameter']=='DF_lambda']['Value'].values[0])\n",
    "daily_slots = int(float(input_parameters[input_parameters['Parameter']=='daily_slots']['Value'].values[0]))\n",
    "step_size = float(input_parameters[input_parameters['Parameter']=='step_size']['Value'].values[0])\n",
    "solar_pu_cost =float(input_parameters[input_parameters['Parameter']=='solar_pu_cost']['Value'].values[0])\n",
    "wind_pu_cost =float(input_parameters[input_parameters['Parameter']=='wind_pu_cost']['Value'].values[0])\n",
    "market_limit = float(input_parameters[input_parameters['Parameter']=='market_limit']['Value'].values[0])\n",
    "battery_power_capacity =float(input_parameters[input_parameters['Parameter']=='battery_power_capacity']['Value'].values[0])\n",
    "battery_energy_capacity =float(input_parameters[input_parameters['Parameter']=='battery_energy_capacity']['Value'].values[0])\n",
    "battery_initial_state = float(input_parameters[input_parameters['Parameter']=='battery_initial_state']['Value'].values[0])\n",
    "clusters_rqd = ast.literal_eval(input_parameters[input_parameters['Parameter']=='clusters_rqd']['Value'].values[0])\n",
    "mode=ast.literal_eval(input_parameters[input_parameters['Parameter']=='mode']['Value'].values[0])\n",
    "inconvenience_cost =ast.literal_eval(input_parameters[input_parameters['Parameter']=='inconvenience_cost']['Value'].values[0])\n",
    "output_folder_name =(input_parameters[input_parameters['Parameter']=='Output Folder Name']['Value'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5a72c",
   "metadata": {},
   "source": [
    "# Section 3 - Trigger calculation for DR and DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927647c2",
   "metadata": {},
   "source": [
    "\n",
    "Creates triggers for each cluster based on slotwise per unit generation cost\n",
    "For DR - triggers are generated for slots with pu generation cost is more than the threshold value\n",
    "For DF - triggers are generated for slots with pu generation cost higher than upper limit or lower than lower limit\n",
    "Triggers are created in a way to shift the demand from slots with higher pu generation cost to slots with lower generation cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81f43bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trigger_calculation(pu_gen_cost, tariff,mode,n):\n",
    "    \n",
    "    # pricing signal calculation based on slot wise per unit generation cost (Step fucntion)\n",
    "    gencdc = pu_gen_cost.sort_values().reset_index()\n",
    "    gen_cost_dc = gencdc.iloc[:,1]\n",
    "    \n",
    "    mean_cost_ub = gen_cost_dc[int(len(gen_cost_dc)*0.60)] # top 0.4 % slots with higher pu_gen_cost\n",
    "    mean_cost_lb = gen_cost_dc[int(len(gen_cost_dc)*0.40)] # bottom 0.5 % slots with higher pu_gen_cost   \n",
    "    \n",
    "#     step_size = 0.15\n",
    "    triggers = pd.DataFrame(index = range(len(pu_gen_cost)), columns = tariff.columns)\n",
    "    DF_trigger =np.zeros(len(pu_gen_cost)) \n",
    "    DR_incentive =np.zeros(len(pu_gen_cost)) \n",
    "    \n",
    "    for s in range(len(pu_gen_cost)):\n",
    "                \n",
    "        if pu_gen_cost[s] >=mean_cost_ub:\n",
    "            DR_incentive [s] =round((pu_gen_cost[s] - mean_cost_ub)/step_size)\n",
    "            DF_trigger [s] =round((pu_gen_cost[s] -mean_cost_ub)/step_size)\n",
    "        elif pu_gen_cost[s]<=mean_cost_lb:\n",
    "            DF_trigger [s] = round((pu_gen_cost[s] - mean_cost_ub)/step_size)\n",
    "        else:\n",
    "            DR_incentive [s] = 0\n",
    "            DF_trigger [s] = 0\n",
    "     \n",
    "    \n",
    "#     plt.plot(DR_incentive*DR_lambda)\n",
    "    for i in range(len(tariff.columns)):\n",
    "        if mode[i]=='DR':\n",
    "            triggers.iloc[:,i] =  DR_incentive[:]*(base_incenitve_DR +n* DR_lambda) + tariff.iloc[:,i]\n",
    "        elif mode[i] =='DF':\n",
    "            triggers.iloc[:,i] = tariff.iloc[:,i] + DF_trigger*(base_incenitve_DF+n*DF_lambda)\n",
    "        else:\n",
    "            triggers.iloc[:,i] = DR_incentive[:]*(base_incenitve_DR+n* DR_lambda)\n",
    "                \n",
    "            \n",
    "    return triggers\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbbbc0",
   "metadata": {},
   "source": [
    "# Section 4 - Consumer load optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe469d",
   "metadata": {},
   "source": [
    "Optimises the cluster level load profiles based on triggers, DF/DR program and flexibility to minimise the consumer bills\n",
    "\n",
    "Objective: Minimise (consumer bill + inconvenience to consumers) / maximise (DR incentive -inconvenience to consumers)\n",
    "\n",
    "Constraints: \n",
    "1. DF program - Daily total energy use must not change from BAU\n",
    "2. DR program - % limits on reduction in daily total energy \n",
    "3. % Flexibility - range within which the load shape can be modulated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87fa850c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_optimisation_aggregate(cluster_triggers,mode,flexibility,clustered_profile,tarifff,inconvenience_cost):\n",
    "    total_slots = len(tariff)  \n",
    "\n",
    "    num_columns = len(clustered_profile.columns)\n",
    "\n",
    "\n",
    "    optimized_clusters = pd.DataFrame(columns = clustered_profile.columns, index = range(len(clustered_profile)))\n",
    "    load_billing= pd.DataFrame(columns = clustered_profile.columns, index = range(len(clustered_profile)))\n",
    "    start = time.time()\n",
    "    for c in range(num_columns):\n",
    "        cluster_profile = clustered_profile.iloc[:,c].reset_index(drop=True)\n",
    "        tariff_structure =cluster_triggers.iloc[:,c].reset_index(drop=True)\n",
    "        opt_profile = load_optimisation(tariff_structure, cluster_profile, flex[c],mode[c],inconvenience_cost[c])\n",
    "        optimized_clusters.iloc[:,c] = opt_profile[0]\n",
    "        if mode[c] == 'DRR':\n",
    "            load_billing.iloc[:,c] = opt_profile[0] - cluster_profile\n",
    "        else:\n",
    "            load_billing.iloc[:,c] = optimized_clusters.iloc[:,c]\n",
    "                 \n",
    "    end = time.time()\n",
    "    \n",
    "    tff = cluster_triggers\n",
    "    tff.columns = optimized_clusters.columns\n",
    "    \n",
    " \n",
    "    bills = 1000*load_billing.mul(tff)\n",
    "    \n",
    "    for c in range(num_columns):\n",
    "        if mode[c] =='DRR':\n",
    "            bills.iloc[:,c] = bills.iloc[:,c]+1000*tarifff.iloc[:,c]*optimized_clusters.iloc[:,c]\n",
    "    \n",
    "    return optimized_clusters, bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1ba9f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_optimisation(triggers, clustered_profile, flexibility, mode,inconvenience_cost):\n",
    "    \n",
    "    num_hours = len(clustered_profile)\n",
    "#     daily_slots = 24\n",
    "    num_days = int(num_hours/daily_slots)\n",
    "\n",
    "    if mode == 'DF':\n",
    "        Bill_optimization = LpProblem(\"Bill_optimization\", LpMinimize)\n",
    "   \n",
    "        shifted_load = [LpVariable(f\"{t}_shifted_load\", lowBound=clustered_profile[t]*(1-flexibility),upBound = clustered_profile[t]*(1+flexibility)) for t in range(num_hours)]\n",
    "\n",
    "        total_shift = [LpVariable(f\"{t}_total_shift\") for t in range(num_hours)]        \n",
    "   \n",
    "      # Constraint 1 Total energy consumption is same for the day\n",
    "        for d in range(num_days):\n",
    "            Bill_optimization += lpSum(shifted_load[t+d*daily_slots] for t in range(daily_slots)) == clustered_profile[d*daily_slots:(d+1)*daily_slots].sum()\n",
    "    \n",
    "      # Constraint 2 total shifted energy for calculating inconvinence\n",
    "        for t in range(num_hours):\n",
    "                   Bill_optimization += total_shift[t]>=clustered_profile[t] - shifted_load[t]\n",
    "                   Bill_optimization += total_shift[t]>=-clustered_profile[t] + shifted_load[t]\n",
    "       \n",
    "        \n",
    "#      # inconvinience to consumer  \n",
    "        incovinience = lpSum(total_shift[t]*inconvenience_cost for t in range(num_hours))\n",
    "    \n",
    "        #Objective fucntcion (minimise the bill i.e. electricity cost to consumers + inconvinence)\n",
    "        Bill_optimization += lpSum(shifted_load[t] * triggers[t] for t in range(num_hours)) +incovinience                         \n",
    "        \n",
    "        \n",
    "        Bill_optimization.solve()\n",
    "\n",
    "    \n",
    "        opt_load = pd.DataFrame(index=range(len(shifted_load)), columns=range(1))\n",
    "        \n",
    "    elif mode == 'DR':\n",
    "    \n",
    "        Bill_optimization = LpProblem(\"Bill_optimization\", LpMinimize)\n",
    "      \n",
    "        shifted_load = [LpVariable(f\"{t}_shifted_load\", lowBound=clustered_profile[t]*(1-flexibility),upBound = clustered_profile[t]) for t in range(num_hours)]\n",
    "        total_shift = lpSum(clustered_profile[t] -shifted_load[t] for t in range(num_hours))\n",
    "\n",
    "      # Objective fucntcion (minimise the bill i.e. electricity cost to consumers + inconvinence)\n",
    "        Bill_optimization += lpSum(shifted_load[t] *triggers[t] for t in range(num_hours)) +total_shift*inconvenience_cost\n",
    "   \n",
    "  \n",
    "      # Constraint 1 Total energy reduction limitted to 5 % of total baseline consumption\n",
    "        for d in range(num_days):\n",
    "            Bill_optimization += lpSum(shifted_load[t+d*daily_slots] for t in range(daily_slots)) >= (1-0.05)*clustered_profile[d*daily_slots:(d+1)*daily_slots].sum()\n",
    "    \n",
    "        Bill_optimization.solve()\n",
    "\n",
    "        opt_load = pd.DataFrame(index=range(len(shifted_load)), columns=range(1))\n",
    "        \n",
    "    else:\n",
    "            \n",
    "        Bill_optimization = LpProblem(\"Bill_optimization\", LpMinimize)\n",
    "    \n",
    "        shifted_load = [LpVariable(f\"{t}_shifted_load\", lowBound=clustered_profile[t]*(1-flexibility),upBound = clustered_profile[t]) for t in range(num_hours)]\n",
    "        total_shift = lpSum(clustered_profile[t] -shifted_load[t] for t in range(num_hours))\n",
    "        \n",
    "        # Objective fucntcion (minimise the bill i.e. electricity cost to consumers + inconvinence)\n",
    "    \n",
    "        Bill_optimization += lpSum((-clustered_profile[t]+shifted_load[t]) * triggers[t] for t in range(num_hours))+ total_shift*inconvenience_cost\n",
    "     \n",
    "        # Constraint 1 Total energy reduction limitted to 5 % of total baseline consumption\n",
    "  \n",
    "        for d in range(num_days):\n",
    "            Bill_optimization += lpSum(shifted_load[t+d*daily_slots] for t in range(daily_slots)) >= (1-0.05)*clustered_profile[d*daily_slots:(d+1)*daily_slots].sum() \n",
    "    \n",
    "        Bill_optimization.solve()\n",
    "    \n",
    "        opt_load = pd.DataFrame(index=range(len(shifted_load)), columns=range(1))\n",
    "        \n",
    "    \n",
    "    print(\"Demand optimisation Status:\", LpStatus[Bill_optimization.status]) \n",
    "\n",
    "    for i in range(len(shifted_load)):\n",
    "        opt_load.iloc[i,0]=shifted_load[i].varValue\n",
    "        \n",
    "    return opt_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda38a02",
   "metadata": {},
   "source": [
    "# Section 5 - Generation cost optimisation - Security constrained economic dispatch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26edac4e",
   "metadata": {},
   "source": [
    "Disptach model for scheduling conventional generators for net load requirment\n",
    "\n",
    "Objective: Minimise generation cost\n",
    "\n",
    "Constraints: \n",
    "1. technical minimum of generators\n",
    "2. supply - demand balance\n",
    "3. ramping limits for generators\n",
    "4. limits on individual generation capacity\n",
    "4. limits on power purchased from IEX - optional\n",
    "5. battery energy storage system - limits on energy and power capacities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "001a0c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_generation_cost(demand,n):    \n",
    "    #RE Power generation profiles\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    solar=re['Solar']\n",
    "    wind=re['Wind']\n",
    "    RE=solar+wind\n",
    "\n",
    "    # Net demand for conventional genration\n",
    "    net_demand = demand - re.sum(axis=1)\n",
    "\n",
    "    num_plants=len(ppa['Capacity'])\n",
    "   \n",
    "  \n",
    "    \n",
    "    generation_capacity = ppa['Capacity']\n",
    "    technical_minimum = ppa['Technical_min']\n",
    "    fixed_cost = ppa['Fixed cost']  # Fixed cost for each plant\n",
    "    Variable_cost=ppa['Variable cost']\n",
    "   \n",
    "  \n",
    "    total_daily_energy = projected_demand.iloc[:,:].sum()\n",
    "    cost_matrix = pd.DataFrame()\n",
    "\n",
    "    ramping_up = ppa['Ramping_up'] # Ramping up limit for each plant\n",
    "    ramping_down = ppa['Ramping down']  # Ramping down limit for each plant\n",
    "    \n",
    "\n",
    "    num_plants=len(generation_capacity)\n",
    "    num_hours=len(demand.values)\n",
    "#     print(num_hours)\n",
    "  \n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "    problem = LpProblem(\"Power_Generation_Optimization\", LpMinimize)\n",
    "\n",
    "    # Define the decision variables\n",
    "    schedule = [[LpVariable(f\"Schedule_{t}_{p}\") for p in range(num_plants)] \n",
    "                for t in range(num_hours)]\n",
    "    market_drawl = [LpVariable(f\"Market_{t}\") for t in range(num_hours)]\n",
    "    b_soc = [LpVariable(f\"b_soc_{t}\",lowBound=0, upBound = battery_energy_capacity) for t in range(num_hours+1)]\n",
    "               \n",
    "    \n",
    "\n",
    "    # Set the objective function\n",
    "    problem += lpSum(schedule[t][p] * Variable_cost[p] for t in range(num_hours) for p in range(num_plants))+lpSum(market_drawl[t]*market_price['rate'][t] for t in range(num_hours))\n",
    "    \n",
    "    # Add the constraints\n",
    "\n",
    "    #Constraint 1  - ramping up and down constraints 1% for thermal, 3% for gas, 10% for hydro\n",
    "    for t in range(num_hours - 1):\n",
    "        for p in range(num_plants):\n",
    "            del_schedule = schedule[t+1][p] - schedule[t][p]\n",
    "            problem += ramping_down[p] <= del_schedule <= ramping_up[p]\n",
    "\n",
    "    #Constraint 2 -  technical Minimum\n",
    "    for t in range(num_hours):\n",
    "        for p in range(num_plants):\n",
    "            problem += schedule[t][p]>=technical_minimum[p]\n",
    "\n",
    "\n",
    "    #Constraint 3 - Total generation in slot i = Total demand in slot i\n",
    "    for t in range(num_hours):\n",
    "        problem += lpSum(schedule[t][p] for p in range(num_plants)) ==net_demand[t]-market_drawl[t]-b_soc[t]+b_soc[t+1]\n",
    "        \n",
    "\n",
    "    #Constraint 4 - Generation should not exceed capacity\n",
    "    for t in range(num_hours):\n",
    "        for p in range(num_plants):\n",
    "            problem += schedule[t][p] <= ppa['Capacity'][p]\n",
    "            \n",
    "     #constraint 5 - sales in market power should be less thanmarket limit of net demand\n",
    "    for t in range(num_hours):\n",
    "        problem +=market_drawl[t] <=market_limit*net_demand[t]\n",
    "#         problem +=market_drawl[t] >=-market_limit*net_demand[t]\n",
    "        problem +=market_drawl[t] >=0\n",
    "        \n",
    "#     #constraint 7 - battery charging and discharging constriants\n",
    "\n",
    "    for t in range(num_hours):\n",
    "        b_power = b_soc[t]-b_soc[t+1]\n",
    "        problem+= -battery_power_capacity<=b_power<=battery_power_capacity\n",
    "    \n",
    "           \n",
    "    # Solve the problem\n",
    "    problem.solve()\n",
    "\n",
    "    # Check the status of the solution\n",
    "    \n",
    "    print(\"Generation optimisation Status:\", LpStatus[problem.status])  \n",
    "\n",
    "    end_time0=time.time()\n",
    " #______________________________________________________________________________________________________   \n",
    "    # saving variable values in dataframe\n",
    "\n",
    "    schedule_gen = pd.DataFrame(index=range(num_hours), columns=range(num_plants))\n",
    "    market_power = pd.DataFrame(index=range(num_hours))\n",
    "    battery_profile = pd.DataFrame(index=range(num_hours))\n",
    "    \n",
    "   \n",
    "    for t in range(num_hours):\n",
    "        for p in range(num_plants):\n",
    "            schedule_gen.at[t, p] = schedule[t][p].varValue\n",
    "        market_power.at[t,0] = market_drawl[t].varValue\n",
    "        battery_profile.at[t,0]=b_soc[t+1].varValue\n",
    "        \n",
    "       \n",
    "    # dataframe to csv\n",
    "    gen_schedule_path = os.path.join(OUTPUT_PATH,output_folder_name,\"Generation schedules\")\n",
    "    if n==0:\n",
    "        os.makedirs(gen_schedule_path)\n",
    "        \n",
    "    schedule_gen.to_csv(gen_schedule_path + \"/schedule_output_\" + str(n) + \".csv\", index=False)\n",
    "    \n",
    "    # generation cost = schedule of plant * variable_cost\n",
    "    re_cost = solar*solar_pu_cost + wind*wind_pu_cost\n",
    "    market_cost = market_power.iloc[:,0]*market_price.iloc[:,0]\n",
    "    total_generation_cost = np.dot(np.array(schedule_gen.iloc[:,:]),np.array(Variable_cost[:])) + re_cost +market_cost\n",
    "    # cost_without_RE = total_generation_cost - re_cost\n",
    "    \n",
    "    # per unit generation cost = total generation cost /total units\n",
    "    per_unit_generation_cost = total_generation_cost/(projected_demand['demand'] - re.sum(axis=1))\n",
    "    \n",
    "    end_time= time.time()\n",
    "    \n",
    "    total_time1 = end_time0 - start_time\n",
    "    total_time2 = end_time - start_time\n",
    "#     print('Time taken for optimisation:',total_time1)\n",
    "    print('Total time elapsed:',total_time2)\n",
    "\n",
    "    return per_unit_generation_cost, market_power, battery_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcb853",
   "metadata": {},
   "source": [
    "# Section 6 - RE forecast module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5322ce",
   "metadata": {},
   "source": [
    "AN- based timeseries forecasting module - Creates weather forecast for GHI, wind Speed, temperature specific to geographical locations and estimates the solar and wind energy generation forecaste for desired time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a324bda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: D:\\MpEnsystems\\SE4ALL DF 2024 - 2025\\DF model\\input files for model\\input data\n",
      "['demand.csv', 'Generation module test', 'Generation_stack.xlsx', 'Info_Solar.csv', 'Info_Wind.csv', 'input_parameters.csv', 'market_rate.xlsx', 'meter data', 'RE.xlsx', 'residential_1.csv', 'tariff.csv', 'tariff_10.csv', '~$Generation_stack.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# Solar & Wind Power Forecasting Using LSTM (Hourly) - GHI, Temperature, Wind\n",
    "\n",
    "cwd = os.path.abspath(INPUT_PATH) \n",
    "print(\"Current Working Directory:\",cwd)\n",
    "files = os.listdir(cwd)\n",
    "print(files)\n",
    "\n",
    "final_SolarPower = pd.DataFrame()\n",
    "final_WindPower = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('Plant.csv'):\n",
    "        print(file)\n",
    "        set_seed(455)   # To set the random seed for reproducibility purposes\n",
    "        np.random.seed(455)\n",
    "        file_path = os.path.join(cwd, file)\n",
    "        dataset = pd.read_csv(file_path,parse_dates=[\"Timestamp\"]).drop([],axis=1)\n",
    "        dataset = dataset.sort_values(by='Timestamp')\n",
    "        dataset = dataset.set_index(\"Timestamp\")\n",
    "        print(dataset.head())\n",
    "        print(dataset.describe())  # analyze the data in depth\n",
    "        dataset.isna().sum()       # Determines the missing values in the dataset      \n",
    "        \n",
    "        tstart = 2001\n",
    "        tend = 2022\n",
    "        def train_test_plot1(dataset, tstart, tend):\n",
    "            dataset.loc[f\"{tstart}\":f\"{tend}\", \"Temperature\"].plot(figsize=(16,4), legend=True)\n",
    "            dataset.loc[f\"{tend+1}\":, \"Temperature\"].plot(figsize=(16, 4), legend=True)\n",
    "            plt.legend([f\"Train (Before {tend+1})\", f\"Test ({tend+1} and beyond)\"])\n",
    "            plt.title(\"Temperature (°C)\")\n",
    "            plt.show()\n",
    "        train_test_plot1(dataset,tstart,tend)\n",
    "        \n",
    "        def train_test_plot2(dataset, tstart, tend):\n",
    "            dataset.loc[f\"{tstart}\":f\"{tend}\", \"GHI\"].plot(figsize=(16,4), legend=True)\n",
    "            dataset.loc[f\"{tend+1}\":, \"GHI\"].plot(figsize=(16, 4), legend=True)\n",
    "            plt.legend([f\"Train (Before {tend+1})\", f\"Test ({tend+1} and beyond)\"])\n",
    "            plt.title(\"Radiation (kWh/m2/day)\")\n",
    "            plt.show()\n",
    "        train_test_plot2(dataset,tstart,tend)\n",
    "        \n",
    "        def train_test_plot3(dataset, tstart, tend):\n",
    "            dataset.loc[f\"{tstart}\":f\"{tend}\", \"Wind Speed\"].plot(figsize=(16,4), legend=True)\n",
    "            dataset.loc[f\"{tend+1}\":, \"Wind Speed\"].plot(figsize=(16, 4), legend=True)\n",
    "            plt.legend([f\"Train (Before {tend+1})\", f\"Test ({tend+1} and beyond)\"])\n",
    "            plt.title(\"Wind Speed (m/s)\")\n",
    "            plt.show()\n",
    "        train_test_plot3(dataset,tstart,tend)\n",
    "        \n",
    "        def train_test_split1(dataset, tstart, tend):\n",
    "            train = dataset.loc[f\"{tstart}\":f\"{tend}\", \"Temperature\"].values\n",
    "            test = dataset.loc[f\"{tend+1}\":, \"Temperature\"].values\n",
    "            return train, test\n",
    "        training_set1, test_set1 = train_test_split1(dataset, tstart, tend)\n",
    "        \n",
    "        def train_test_split2(dataset, tstart, tend):\n",
    "            train = dataset.loc[f\"{tstart}\":f\"{tend}\", \"GHI\"].values\n",
    "            test = dataset.loc[f\"{tend+1}\":, \"GHI\"].values\n",
    "            return train, test\n",
    "        training_set2, test_set2 = train_test_split2(dataset, tstart, tend)\n",
    "        \n",
    "        def train_test_split3(dataset, tstart, tend):\n",
    "            train = dataset.loc[f\"{tstart}\":f\"{tend}\", \"Wind Speed\"].values\n",
    "            test = dataset.loc[f\"{tend+1}\":, \"Wind Speed\"].values\n",
    "            return train, test\n",
    "        training_set3, test_set3 = train_test_split3(dataset, tstart, tend)\n",
    "        test_set3 = pd.DataFrame(test_set3)\n",
    "        \n",
    "        sc1 = MinMaxScaler(feature_range=(0, 1))\n",
    "        training_set1 = training_set1.reshape(-1, 1)\n",
    "        training_set1_scaled = sc1.fit_transform(training_set1)\n",
    "        sc2 = MinMaxScaler(feature_range=(0, 1))\n",
    "        training_set2 = training_set2.reshape(-1, 1)\n",
    "        training_set2_scaled = sc2.fit_transform(training_set2)\n",
    "        sc3 = MinMaxScaler(feature_range=(0, 1))\n",
    "        training_set3 = training_set3.reshape(-1, 1)\n",
    "        training_set3_scaled = sc3.fit_transform(training_set3)\n",
    "        \n",
    "        def split_sequence(sequence, n_steps):\n",
    "            X, y = list(), list()\n",
    "            for i in range(len(sequence)):\n",
    "                end_ix = i + n_steps\n",
    "                if end_ix > len(sequence) - 1:\n",
    "                    break\n",
    "                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "                X.append(seq_x)\n",
    "                y.append(seq_y)\n",
    "            return np.array(X), np.array(y)\n",
    "        \n",
    "        n_steps = 10\n",
    "        features = 1\n",
    "        epochs_n = 2\n",
    "        \n",
    "        X_train1, y_train1 = split_sequence(training_set1_scaled, n_steps)\n",
    "        X_train2, y_train2 = split_sequence(training_set2_scaled, n_steps)\n",
    "        X_train3, y_train3 = split_sequence(training_set3_scaled, n_steps)\n",
    "        X_train1 = X_train1.reshape(X_train1.shape[0],X_train1.shape[1],features)\n",
    "        X_train2 = X_train2.reshape(X_train2.shape[0],X_train2.shape[1],features)\n",
    "        X_train3 = X_train3.reshape(X_train3.shape[0],X_train3.shape[1],features)\n",
    "        \n",
    "        model_lstm1 = Sequential()   # To create a linear stack of layers for the model\n",
    "        model_lstm1.add(Input(shape=(n_steps, features))) \n",
    "        model_lstm1.add(LSTM(units=125, activation=\"tanh\"))\n",
    "        model_lstm1.add(Dense(units=1))\n",
    "        model_lstm1.compile(optimizer=\"RMSprop\", loss=\"mse\")\n",
    "        model_lstm1.summary()\n",
    "        model_lstm1.fit(X_train1, y_train1, epochs=epochs_n, batch_size=32)\n",
    "        \n",
    "        model_lstm2 = Sequential()  \n",
    "        model_lstm2.add(Input(shape=(n_steps, features))) \n",
    "        model_lstm2.add(LSTM(units=125, activation=\"tanh\"))\n",
    "        model_lstm2.add(Dense(units=1))\n",
    "        model_lstm2.compile(optimizer=\"RMSprop\", loss=\"mse\")\n",
    "        model_lstm2.summary()\n",
    "        model_lstm2.fit(X_train2, y_train2, epochs=epochs_n, batch_size=32)\n",
    "        \n",
    "        model_lstm3 = Sequential()  \n",
    "        model_lstm3.add(Input(shape=(n_steps, features))) \n",
    "        model_lstm3.add(LSTM(units=125, activation=\"tanh\"))\n",
    "        model_lstm3.add(Dense(units=1))\n",
    "        model_lstm3.compile(optimizer=\"RMSprop\", loss=\"mse\")\n",
    "        model_lstm3.summary()\n",
    "        model_lstm3.fit(X_train3, y_train3, epochs=epochs_n, batch_size=32)\n",
    "        \n",
    "        dataset_total1 = dataset.loc[:,\"Temperature\"]\n",
    "        inputs1 = dataset_total1[len(dataset_total1) - len(test_set1) - n_steps :].values\n",
    "        inputs1 = inputs1.reshape(-1, 1)\n",
    "        inputs1 = sc1.transform(inputs1)\n",
    "        X_test1, y_test1 = split_sequence(inputs1, n_steps)\n",
    "        X_test1 = X_test1.reshape(X_test1.shape[0], X_test1.shape[1], features)\n",
    "        predicted_Temperature_h = model_lstm1.predict(X_test1)\n",
    "        predicted_Temperature_h = sc1.inverse_transform(predicted_Temperature_h)\n",
    "        predicted_Temperature_h = pd.DataFrame(predicted_Temperature_h)\n",
    "        \n",
    "        dataset_total2 = dataset.loc[:,\"GHI\"]\n",
    "        inputs2 = dataset_total2[len(dataset_total2) - len(test_set2) - n_steps :].values\n",
    "        inputs2 = inputs2.reshape(-1, 1)\n",
    "        inputs2 = sc2.transform(inputs2)\n",
    "        X_test2, y_test2 = split_sequence(inputs2, n_steps)\n",
    "        X_test2 = X_test2.reshape(X_test2.shape[0], X_test2.shape[1], features)\n",
    "        predicted_GHI_h = model_lstm2.predict(X_test2)\n",
    "        predicted_GHI_h = sc2.inverse_transform(predicted_GHI_h)\n",
    "        predicted_GHI_h = pd.DataFrame(predicted_GHI_h)\n",
    "        predicted_GHI_h[predicted_GHI_h < 1] = 0\n",
    "        \n",
    "        dataset_total3 = dataset.loc[:,\"Wind Speed\"]\n",
    "        inputs3 = dataset_total3[len(dataset_total3) - len(test_set3) - n_steps :].values\n",
    "        inputs3 = inputs3.reshape(-1, 1)\n",
    "        inputs3 = sc3.transform(inputs3)\n",
    "        X_test3, y_test3 = split_sequence(inputs3, n_steps)\n",
    "        X_test3 = X_test3.reshape(X_test3.shape[0], X_test3.shape[1], features)\n",
    "        predicted_WS_h = model_lstm3.predict(X_test3)\n",
    "        predicted_WS_h = sc3.inverse_transform(predicted_WS_h)\n",
    "        predicted_WS_h = pd.DataFrame(predicted_WS_h)\n",
    "        predicted_WS_h[predicted_WS_h < 0] = 0\n",
    "        print(predicted_WS_h)\n",
    "        def return_rmse1(test1, predicted1):\n",
    "            rmse1 = np.sqrt(mean_squared_error(test1, predicted1))\n",
    "            print(\"The root mean squared error in temperature is {:.2f}%.\".format(rmse1))\n",
    "        \n",
    "        def return_rmse2(test2, predicted2):\n",
    "            rmse2 = np.sqrt(mean_squared_error(test2, predicted2))\n",
    "            print(\"The root mean squared error in GHI is {:.2f}%.\".format(rmse2))\n",
    "        \n",
    "        def return_rmse3(test3, predicted3):\n",
    "            rmse3 = np.sqrt(mean_squared_error(test3, predicted3))\n",
    "            print(\"The root mean squared error in Wind Speed is {:.2f}%.\".format(rmse3))\n",
    "            \n",
    "        return_rmse1(test_set1,predicted_Temperature_h)\n",
    "        return_rmse2(test_set2,predicted_GHI_h)\n",
    "        return_rmse3(test_set3,predicted_WS_h)\n",
    "        \n",
    "        \n",
    "        # -------------- GHI-POA conversion (Transposition factor) ------------\n",
    "        \n",
    "        from pvlib import location\n",
    "        from pvlib import irradiance\n",
    "        import pytz\n",
    "        import itertools\n",
    "        \n",
    "        with open(os.path.join(cwd,\"Info_Solar.csv\"), 'r') as tempFile:\n",
    "            info_Solar = pd.read_csv(io.StringIO(tempFile.read()))\n",
    "            info_Solar = info_Solar.set_index('Parameter')\n",
    "        print('float0')    \n",
    "        print(info_Solar)\n",
    "        tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "        lat, lon = float(info_Solar.iloc[0].iloc[0]),float(info_Solar.iloc[1].iloc[0])\n",
    "        site = location.Location(lat, lon, tz=tz)\n",
    "        print('float1')    \n",
    "        def get_irradiance(site_location,date, tilt, surface_azimuth):\n",
    "            times = pd.date_range(date, freq='10min', periods=6*24,\n",
    "                                  tz=site_location.tz)\n",
    "            clearsky = site_location.get_clearsky(times)\n",
    "            solar_position = site_location.get_solarposition(times=times)\n",
    "            POA_irradiance = irradiance.get_total_irradiance(\n",
    "                surface_tilt=tilt,\n",
    "                surface_azimuth=surface_azimuth,\n",
    "                dni=clearsky['dni'],\n",
    "                ghi=clearsky['ghi'],\n",
    "                dhi=clearsky['dhi'],\n",
    "                solar_zenith=solar_position['apparent_zenith'],\n",
    "                solar_azimuth=solar_position['azimuth'])\n",
    "            return pd.DataFrame({'GHI': clearsky['ghi'],\n",
    "                                 'POA': POA_irradiance['poa_global']})\n",
    "        \n",
    "        dates = pd.Series(pd.date_range(str(2023) + \"-01-01\", str(2023) + \"-12-31\", freq=\"D\"))\n",
    "        dates = dates.to_frame(name='Timestamp')\n",
    "        dates['Timestamp'] = dates['Timestamp'].dt.strftime('%d/%m/%Y')\n",
    "        \n",
    "        Final_irr = pd.DataFrame()\n",
    "        for i in range(365):\n",
    "            Total_irr = get_irradiance(site,dates.iloc[i-1,0], 20, 0)\n",
    "            Total_irr = Total_irr.reset_index(drop=True)\n",
    "            Final_irr = pd.concat([Final_irr,Total_irr],axis=1)\n",
    "        \n",
    "        Temp_irradiance = get_irradiance(site,dates.iloc[0,0], 20, 0)\n",
    "        Final_irr.index = Temp_irradiance.index.strftime(\"%H:%M:%S\")\n",
    "        Final_irr = Final_irr.transpose()\n",
    "        GHI = Final_irr[0::2] \n",
    "        POA = Final_irr[1::2] \n",
    "        GHI = GHI.reset_index(drop=True)\n",
    "        POA = POA.reset_index(drop=True)\n",
    "        TF_10min = POA/GHI\n",
    "        TF_10min = TF_10min.set_index(dates.iloc[:,0]) \n",
    "        \n",
    "        TF_hr = pd.DataFrame()\n",
    "        for x in range(0,144,6):\n",
    "            TF_hr0 = (TF_10min.iloc[:, x:x+5].mean(axis=1))\n",
    "            TF_hr0 = TF_hr0.to_frame()\n",
    "            TF_hr = pd.concat([TF_hr,TF_hr0],axis=1)\n",
    "        \n",
    "        myRange = np.arange(00,24,1)\n",
    "        df0 = (pd.DataFrame({\"numbers\": myRange})).transpose()\n",
    "        TF_hr.columns = df0.columns \n",
    "        \n",
    "        TF_d = TF_hr.mean(axis=1) \n",
    "        TF_d = TF_d.to_frame()\n",
    "        # ---------------------------------------------------------------------\n",
    "        \n",
    "        def dataframe_to_row_wise(df):\n",
    "            \n",
    "            row_wise_elements = []              # Empty list to store the row-wise elements\n",
    "            for index, row in df.iterrows():    # Iterate through each row in the DataFrame\n",
    "                for element in row:             # Append each element in the row to the list\n",
    "                    row_wise_elements.append(element)\n",
    "            return row_wise_elements\n",
    "        \n",
    "        data = TF_hr\n",
    "        df = pd.DataFrame(data)\n",
    "        row_wise = dataframe_to_row_wise(df)\n",
    "        TF_hr_new = pd.DataFrame(row_wise, columns=['Value'])\n",
    "\n",
    "        # xxxxxxxxxxxxxxxxxx Transposition Factor End xxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "        predicted_GHI_h = predicted_GHI_h.rename(columns={0: \"Value\"})\n",
    "        TF_hr_new = TF_hr_new.fillna(1)\n",
    "        estimated_POA_h = TF_hr_new * predicted_GHI_h\n",
    "        estimated_POA_d = (estimated_POA_h*3600*10)/(1000*3600)\n",
    "        # ---------------------- Solar Power calculations ---------------------\n",
    "        # From Datasheet\n",
    "        Pnom = int(info_Solar.iloc[2].iloc[0])             # rated power output of the PV module under standard test conditions [kW]\n",
    "        nDRT = float(info_Solar.iloc[3].iloc[0])         # PV derating factor [%] (soiling, wiring losses, shading, snow cover, aging etc.)\n",
    "        alpha = float(info_Solar.iloc[4].iloc[0])     # temperature coefficient of power [%/°C]\n",
    "        gamma = float(info_Solar.iloc[5].iloc[0])          # determined by the mounting type of the system\n",
    "        A_PV = float(info_Solar.iloc[6].iloc[0])              # surface area of the PV module [m2]\n",
    "        Tc_NOCT = 45          # nominal operating cell temperature [°C]\n",
    "        Ta_NOCT = 20          # ambient temperature at which the NOCT is defined [20°C]\n",
    "        Tc_STC = 25          # cell temperature under standard test conditions [25°C]\n",
    "        GT_STC = 1           # the radiation at standard test conditions [1 kW/m2]\n",
    "        GT = estimated_POA_d # solar radiation striking the PV array [kW/m2]\n",
    "        GT_NOCT = 0.8         # solar radiation at which the NOCT is defined [0.8 kW/m2]\n",
    "        Ta = predicted_Temperature_h # ambient temperature [°C]\n",
    "        Tau_alpha = 0.9       # product of the solar absorptance and the solar transmittance is 0.9 or 90%\n",
    "        \n",
    "        nmp_STC = Pnom / (A_PV*GT_STC) / 100 # efficiency of the PV module under standard test conditions [%]\n",
    "        \n",
    "        U0 = 29     # constant heat transfer component (W/m2K) (Free-standing:29, Semi integrated with airduct behind: 20, Fully insulated back: 15)\n",
    "        U1 = 0      # convective heat transfer component (W/m3sK) (Wind loss factor is 0 for all )\n",
    "        WS = 1      # Typical wind speed (m/s)\n",
    "        Ta = Ta.rename(columns={0: \"Value\"})\n",
    "        \n",
    "#         Tc = Ta + estimated_POA_h * ((Tau_alpha*(1-nmp_STC))/(U0 + WS*U1))\n",
    "#         Pdc = Pnom*nDRT*(GT/GT_STC)*(1+alpha*(Tc-Tc_STC))\n",
    "#         spGen = Pdc/Pnom\n",
    "#         PR = (spGen/GT)*100\n",
    "#         print(PR)\n",
    "#         PR['Value'] = PR['Value'].apply(lambda x: \"{:,.2f}%\".format(x))\n",
    "        \n",
    "        Tc = Ta + estimated_POA_h * ((Tau_alpha*(1-nmp_STC))/(U0 + WS*U1))\n",
    "        Pdc = Pnom*nDRT*(GT/GT_STC)*(1+alpha*(Tc-Tc_STC))\n",
    "        Pac = 0.95*Pdc               # Typical losses taken as 5% (Other losses considered in nDRT)\n",
    "        spGen = Pac/Pnom\n",
    "        PR = (spGen/GT)*100\n",
    "        PR['Value'] = PR['Value'].apply(lambda x: \"{:,.2f}%\".format(x))\n",
    "        \n",
    "        Pac = Pac.rename(columns={\"Value\": \"AC Power (kW)\"})\n",
    "        spGen = spGen.rename(columns={\"Value\": \"spGen (kWh/kWp/day)\"}) \n",
    "        PR = PR.rename(columns={\"Value\": \"PR (%)\"})\n",
    "        \n",
    "        Pdc = Pdc.rename(columns={0: \"DC Power (kW)\"})\n",
    "        spGen = spGen.rename(columns={0: \"spGen (kWh/kWp/day)\"}) \n",
    "        PR = PR.rename(columns={0: \"PR (%)\"})\n",
    "        \n",
    "        # ----------------------  Wind Power calculations ---------------------\n",
    "        with open(os.path.join(cwd,\"Info_Wind.csv\"), 'r') as tempFile2:\n",
    "            info_Wind = pd.read_csv(io.StringIO(tempFile2.read()))\n",
    "            info_Wind = info_Wind.set_index('Parameter')\n",
    "        Prtdwn = float(info_Wind.iloc[2].iloc[0])     # rated power of wind turbine 4kW\n",
    "        Vctin =  float(info_Wind.iloc[3].iloc[0])       # Cutin windspeed 2.5 m/s; below this no power generation; power generation starts gradually\n",
    "        # Vrtdwn = math.ceil(((2*Prtdwn)/(rho*A_WT))**(1/3))     # Also Weibull distribution can be used to find it\n",
    "        Vrtdwn = float(info_Wind.iloc[4].iloc[0])         # Typical rated wind velocity in m/s\n",
    "        Vctout = float(info_Wind.iloc[5].iloc[0])        # Cutout windspeed 20 m/s; above this no power generation; turbine shut down\n",
    "        \n",
    "        rho = 1.225        # The standard density of air is 1.225 kg/m3\n",
    "        Cp = 0.4           # power coefficient of the turbine (typically between 0.3 and 0.5)\n",
    "        Pi = 3.141592653589793\n",
    "        D = (np.sqrt((4*Prtdwn)/(Pi*rho*(Vrtdwn**3)*Cp)))        # Turbine diameter\n",
    "        A_WT = (Pi*((D/2)**2))       # cross-sectional area of the wind turbine in m2\n",
    "        Pwn = pd.DataFrame({'Wind Power': range(0, 8760)})\n",
    "        \n",
    "        for i in range(0,8760):\n",
    "            \n",
    "            if float(predicted_WS_h.iloc[i,0]) < Vctin or float(predicted_WS_h.iloc[i,0]) > Vctout:\n",
    "                Pwn.iloc[i,:] = 0\n",
    "            elif float(predicted_WS_h.iloc[i,0]) > Vrtdwn:\n",
    "                Pwn.iloc[i,:] = Prtdwn/1000\n",
    "            else:\n",
    "                Pwn.iloc[i,:]  = (0.5*rho*A_WT*(float((float(predicted_WS_h.iloc[i,0]))**3)))/1000\n",
    "        # ------------------------- Total Powers ------------------------------\n",
    "        \n",
    "        final_SolarPower = pd.concat([final_SolarPower,Pac],axis=1)\n",
    "        final_WindPower = pd.concat([final_WindPower,Pwn],axis=1)\n",
    "        \n",
    "        # -------------------------Plotting -----------------------------------\n",
    "        \n",
    "        test_set1 = pd.DataFrame(test_set1, columns =['Temperature'])\n",
    "        test_set2 = pd.DataFrame(test_set2, columns =['GHI'])\n",
    "        test_set1.index = predicted_Temperature_h.index\n",
    "        test_set2.index = predicted_GHI_h.index\n",
    "        test_set3.index = predicted_WS_h.index\n",
    "        \n",
    "        def plot_temperature(test, predicted):\n",
    "            plt.plot(test, color=\"gray\", label=\"Real\")\n",
    "            plt.plot(predicted, color=\"red\", label=\"Predicted\")\n",
    "            plt.title(\"Temperature (°C) Prediction\")\n",
    "            plt.xlabel(\"Hourly timestamp\")\n",
    "            plt.ylabel(\"Temperature (°C)\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "        def plot_radiation(test, predicted):\n",
    "            plt.plot(test, color=\"gray\", label=\"Real\")\n",
    "            plt.plot(predicted, color=\"red\", label=\"Predicted\")\n",
    "            plt.title(\"Radiation (GHI) Prediction\")\n",
    "            plt.xlabel(\"Hourly timestamp\")\n",
    "            plt.ylabel(\"Radiation (GHI)\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "        def plot_power(test):\n",
    "            plt.plot(test, color=\"green\")\n",
    "            plt.title(\"Hourly DC Power Generation Estimation\")\n",
    "            plt.xlabel(\"Hourly timestamp\")\n",
    "            plt.ylabel(\"DC Power (kW)\")\n",
    "            plt.show()\n",
    "            \n",
    "        def plot_spGen(test):\n",
    "            plt.plot(test, color=\"red\")\n",
    "            plt.title(\"Avg Hourly spGen Estimation\")\n",
    "            plt.xlabel(\"Hourly timestamp\")\n",
    "            plt.ylabel(\"spGen (kWh/kWp/day)\")\n",
    "            plt.show()    \n",
    "        \n",
    "        def plot_PR(test):\n",
    "            plt.plot(test, color=\"blue\")\n",
    "            plt.title(\"Avg PR Estimation\")\n",
    "            plt.xlabel(\"Day\")\n",
    "            plt.ylabel(\"PR (%)\")\n",
    "            plt.show()\n",
    "        \n",
    "        def plot_Pwn(test):\n",
    "            plt.plot(test, color=\"green\")\n",
    "            plt.title(\"Hourly Wind Power Generation Estimation\")\n",
    "            plt.xlabel(\"Hourly timestamp\")\n",
    "            plt.ylabel(\"Wind Power (kW)\")\n",
    "            plt.show()\n",
    "        \n",
    "        plot_temperature(test_set1,predicted_Temperature_h)\n",
    "        plot_radiation(test_set2,predicted_GHI_h)\n",
    "        plot_power(Pdc)\n",
    "        plot_spGen(spGen)\n",
    "        plot_Pwn(Pwn)\n",
    "        # ---------------------------------------------------------------------\n",
    "       \n",
    "\n",
    "final_SolarPower['Total_Power'] = final_SolarPower.sum(axis=1)\n",
    "final_WindPower['Total_Power'] = final_WindPower.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eca1cc",
   "metadata": {},
   "source": [
    "# Section 7 - Clustering of load profile data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9d00d",
   "metadata": {},
   "source": [
    "k-means algorithm - creates load patterns from smart meter consumer level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "097317bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_profile_clustering(tariff):\n",
    "    start_time_cl = time.time()\n",
    "    cwd = os.path.abspath(path_for_meter_data)\n",
    "    files = os.listdir(cwd) \n",
    "    print(files)\n",
    "    tarifff = pd.DataFrame()\n",
    "    ci=0\n",
    "    final_clusters = pd.DataFrame()\n",
    "    for file in files:\n",
    "        \n",
    "        if file.endswith('.csv'):\n",
    "            print(f\"Processing file: {file}\") \n",
    "            file_path = os.path.join(cwd, file) \n",
    "            data1 = pd.read_csv(file_path)\n",
    "    \n",
    "            data_load = data1.drop(columns ='slots')\n",
    "#             data_load = data1\n",
    "            max_load = data_load.max()\n",
    "            norm_mvd = data_load/max_load\n",
    "            number_of_meters = len(data_load.columns)\n",
    "#             clusters_rqd = int(input(\"Please enter no. of clusters required for \" + str(file).strip('.csv') + \" category:\"))\n",
    "            cluster_centroids = pd.DataFrame(index=range(len(norm_mvd)),columns = range(clusters_rqd[ci]))\n",
    "            cluster_tariff = pd.DataFrame(index=range(len(norm_mvd)),columns = range(clusters_rqd[ci]))\n",
    "            cluster_centroids = norm_mvd.iloc[:,[random.randint(1, number_of_meters-1) for _ in range(clusters_rqd[ci])]]\n",
    "            \n",
    "            #meter list\n",
    "            meter_list_1 = norm_mvd.columns.tolist()\n",
    "            #cost matrix\n",
    "            cost_matrix = pd.DataFrame(index = range(len(cluster_centroids.columns)), columns = meter_list_1)\n",
    "            \n",
    "            #iterative clustering\n",
    "            number_of_iterations = 15 \n",
    "            \n",
    "            for it in range(number_of_iterations):\n",
    "                for i in range(number_of_meters):\n",
    "                \n",
    "                    for n in range(len(cluster_centroids.columns)):\n",
    "                        cost_matrix.iloc[n,i] = sum(norm_mvd.iloc[:,i] - cluster_centroids.iloc[:,n])**2\n",
    "                \n",
    "                    min_value_indices = np.argmin(np.array(cost_matrix), axis=0)\n",
    "            \n",
    "                for nn in range(len(cluster_centroids.columns)): \n",
    "                    indexes = np.where(min_value_indices == nn)[0]\n",
    "                    if it == number_of_iterations-1:\n",
    "                        cluster_centroids.iloc[:,nn] = data_load.iloc[:,indexes].mean(axis=1)\n",
    "                    else:\n",
    "                        cluster_centroids.iloc[:,nn] = norm_mvd.iloc[:,indexes].mean(axis=1)  \n",
    "                      \n",
    "            \n",
    "            clustered_meters_list = pd.DataFrame(index = range(1),columns = ['C' + str(i) for i in range(1, clusters_rqd[ci]+1)])\n",
    "            for ii in range (len(cluster_centroids.columns)):\n",
    "                indexes = np.where(min_value_indices == ii)[0]\n",
    "                clustered_meters_list.iloc[0,ii] = indexes  \n",
    "            \n",
    "            # cluster_centroids.columns = [str(file).strip('.csv') +'_Cluster-' + str(i) for i in range(1, clusters_rqd+1)]            \n",
    "            cluster_centroids.columns = [(str(file))[:3] +'_Cluster-' + str(i) for i in range(1, clusters_rqd[ci]+1)]\n",
    "            categorywise_cluster = cluster_centroids.to_dict()\n",
    "            for i in range(clusters_rqd[ci]):\n",
    "                tarifff = pd.concat([tarifff,tariff[os.path.splitext(file)[0]]],axis=1)\n",
    "            final_clusters = pd.concat([final_clusters,cluster_centroids],axis=1)\n",
    "            \n",
    "            ci=ci+1\n",
    "            \n",
    "    aggregate_demand_from_clusters = final_clusters.sum(axis=1)\n",
    "    \n",
    "    tariff_df = pd.DataFrame(columns=final_clusters.columns, index = range(len(final_clusters)))\n",
    "    tariff_df.iloc[:,:] = tarifff.iloc[:,:]\n",
    "    bills = final_clusters.iloc[:,:]*tariff_df.iloc[:,:]\n",
    "    \n",
    "            \n",
    "    end_time_cl = time.time()\n",
    "            \n",
    "    print('Total time elapsed: ', end_time_cl -start_time_cl)\n",
    "    return final_clusters, aggregate_demand_from_clusters,bills,indexes,tarifff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f27191d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hospital.csv', 'New folder', 'pww.csv', 'residential.csv']\n",
      "Processing file: hospital.csv\n",
      "Processing file: pww.csv\n",
      "Processing file: residential.csv\n",
      "Total time elapsed:  13.624884128570557\n"
     ]
    }
   ],
   "source": [
    "[consumer_load_clusters, aggregate_demand_from_clusters,cluster_bills,min_indexes,tarifff] =load_profile_clustering(tariff)\n",
    "# print(2000*consumer_load_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb851e",
   "metadata": {},
   "source": [
    "# Section 8 - Algorithm based on hierarchical decision making"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42660d50",
   "metadata": {},
   "source": [
    "Model approach: Hierarchical decision making algorithm is designed to model interaction between utility and consumer for demand flexibility and demand response programs. \n",
    "\n",
    "Step 1. Utility calculates the generation cost estimates for the time period in consideration and identities the time periods with high generation cost and low generation cost.\n",
    "\n",
    "Step 2: Utility creates pricing signals/triggers for consumers to achieve demand modulation\n",
    "\n",
    "Step 3: Consumer data is analysed based on pricing signals/triggers and optimised consumer load profiles are calculated\n",
    "\n",
    "Step 4: Utility calculates the demand considering optimised consumer load profiles and estimates the generation cost.\n",
    "\n",
    "Step 5: Utility calculates the net savings in generation cost after accommodating incentive cost occurred for demand modulation.\n",
    "\n",
    "Step 6: Step 2 to Step 5 are repeated until the net savings in subsequent iterations are converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f3db34af",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "Generation optimisation....\n",
      "Generation optimisation Status: Optimal\n",
      "Total time elapsed: 112.73333191871643\n",
      "489.7043514628059\n",
      "108.2862479381686\n",
      "---------------------------------\n",
      "iteration:  1\n",
      "calculating triggers....\n",
      "Load curves optimisations....\n",
      "Demand optimisation Status: Optimal\n",
      "Demand optimisation Status: Optimal\n",
      "Demand optimisation Status: Optimal\n",
      "Demand optimisation Status: Optimal\n",
      "Demand optimisation Status: Optimal\n",
      "Demand optimisation Status: Optimal\n",
      "Demand optimisation Status: Optimal\n",
      "Demand optimisation Status: Optimal\n",
      "Demand optimisation Status: Optimal\n",
      "Generation optimisation....\n",
      "Generation optimisation Status: Optimal\n",
      "Total time elapsed: 92.63686728477478\n",
      "488.5659740710208\n",
      "108.24361596930885\n",
      "---------------------------------\n",
      "228.9365086555481\n"
     ]
    }
   ],
   "source": [
    "# setting up problem and user inputs for analysis\n",
    "\n",
    "re_forecasting = 0 # 0 if forecasted data is available in csv format, 1 if forecasting is needed                         \n",
    "if re_forecasting ==1:\n",
    "    re['Solar']=final_SolarPower['Total_power']\n",
    "    re['Wind']=final_WindPower['Total_power']\n",
    "\n",
    "start_time = time.time()\n",
    "# create dictionaries to store data in each iteration\n",
    "iterative_tariff_signals ={}\n",
    "iterative_demand ={}\n",
    "iterative_pu_gen_cost = {}\n",
    "iterative_opt_load = {}\n",
    "iterative_cluster_bills = {}\n",
    "iterative_market_power = {}\n",
    "iterative_battery_dispatch ={}\n",
    "iterative_total_gen_cost = {}\n",
    "\n",
    "# initial conditions BAU without DF and DR\n",
    "\n",
    "n= 0 \n",
    "print('iteration: ',n)\n",
    "iterative_tariff_signals[n] = tarifff\n",
    "iterative_demand[n]= projected_demand['demand']\n",
    "print('Generation optimisation....')\n",
    "[pu_gen_cost, market_power, battery_dispatch] = compute_generation_cost(iterative_demand[0],n)\n",
    "iterative_pu_gen_cost[n] = pu_gen_cost\n",
    "\n",
    "# scaling cluster demand by factor of 2000\n",
    "consumer_load_clusters_scaled = consumer_load_clusters*2000\n",
    "aggregate_demand_from_clusters_scaled =consumer_load_clusters_scaled.sum(axis=1)\n",
    "cluster_bills_scaled = cluster_bills*2000000\n",
    "iterative_opt_load[n] = consumer_load_clusters_scaled\n",
    "iterative_market_power[n]=market_power\n",
    "iterative_battery_dispatch[n] = battery_dispatch\n",
    "iterative_cluster_bills [n] = cluster_bills_scaled\n",
    "iterative_total_gen_cost[n] = 1000*(iterative_pu_gen_cost[n]*iterative_demand[n]).sum()\n",
    "\n",
    "fixed_demand = iterative_demand[0] - aggregate_demand_from_clusters_scaled\n",
    "\n",
    "print(iterative_total_gen_cost[n]/1000000000)\n",
    "print(iterative_cluster_bills[n].sum().sum()/1000000000)\n",
    "\n",
    "print('---------------------------------')\n",
    "# Sequesntial process of determing incentive struture by DISCOM and DF/DR response from consumers\n",
    "gen_cost_i = pu_gen_cost\n",
    "number_of_iterations =2\n",
    "n=n+1\n",
    "while n < number_of_iterations:\n",
    "    print('iteration: ',n)\n",
    "    # Incentive / tariff signal estimation\n",
    "    \n",
    "    print('calculating triggers....')\n",
    "    cluster_triggers = trigger_calculation (iterative_pu_gen_cost[0], tarifff,mode,n)\n",
    "    \n",
    "    # Introduce flexibility\n",
    "    print('Load curves optimisations....')\n",
    "    optimised_cluster_loads, cluster_bills_i = load_optimisation_aggregate (cluster_triggers,mode,flex,consumer_load_clusters_scaled,tarifff,inconvenience_cost)\n",
    "    aggregated_opt_cl_load = optimised_cluster_loads.sum(axis = 1)\n",
    "    \n",
    "    # calculate net_demand\n",
    "    demand_i = fixed_demand + aggregated_opt_cl_load\n",
    "    net_demand_i  = demand_i\n",
    "    print('Generation optimisation....')\n",
    "    \n",
    "    # Comput updated gen cost \n",
    "    [pu_gen_cost_i, market_power_i, battery_dispatch_i] = compute_generation_cost(net_demand_i,n)\n",
    "    \n",
    "    gen_cost_i = pu_gen_cost_i\n",
    "    \n",
    "   \n",
    "    iterative_tariff_signals[n] = cluster_triggers\n",
    "    iterative_demand[n]= demand_i\n",
    "    iterative_pu_gen_cost[n] = pu_gen_cost_i\n",
    "    iterative_opt_load[n] = optimised_cluster_loads\n",
    "    iterative_market_power[n] = market_power_i\n",
    "    iterative_battery_dispatch[n] = battery_dispatch_i\n",
    "    iterative_cluster_bills [n] = cluster_bills_i\n",
    "    iterative_total_gen_cost[n] =1000*(iterative_pu_gen_cost[n]*iterative_demand[n]).sum()\n",
    "     \n",
    "    \n",
    "    change_in_DF_consumer_bill = iterative_cluster_bills[n-1].sum() - iterative_cluster_bills[n].sum() # should be positive for consumer benefit\n",
    "    change_in_profit_to_utility= (iterative_total_gen_cost[n-1] - iterative_total_gen_cost[n] - change_in_DF_consumer_bill.sum()) #should be positive for utility benefit\n",
    "    print(iterative_total_gen_cost[n]/1000000000)\n",
    "    print(iterative_cluster_bills[n].sum().sum()/1000000000)\n",
    "    print('---------------------------------')\n",
    "    n=n+1\n",
    "\n",
    "output_dict={\n",
    "           'Demand': iterative_demand,\n",
    "           'Optimal_loads':iterative_opt_load,\n",
    "           'Tariff_signals': iterative_tariff_signals,\n",
    "           'PU_gen_cost': iterative_pu_gen_cost\n",
    "    \n",
    "}\n",
    "\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c147454",
   "metadata": {},
   "source": [
    "# Section 9 - Output visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634fc77",
   "metadata": {},
   "source": [
    "## Saving output as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "52b7134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved succecfully for:tariff_df\n",
      "Output saved succecfully for:demand_df\n",
      "Output saved succecfully for:pugencost_df\n",
      "Output saved succecfully for:optload_df\n",
      "Output saved succecfully for:clusterbills_df\n",
      "Output saved succecfully for:marketpower_df\n",
      "Output saved succecfully for:batterydispatch_df\n",
      "Output saved succecfully for:tariff_df\n",
      "Output saved succecfully for:demand_df\n",
      "Output saved succecfully for:pugencost_df\n",
      "Output saved succecfully for:optload_df\n",
      "Output saved succecfully for:clusterbills_df\n",
      "Output saved succecfully for:marketpower_df\n",
      "Output saved succecfully for:batterydispatch_df\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    ('tariff_df', iterative_tariff_signals),\n",
    "    ('demand_df', iterative_demand),\n",
    "    ('pugencost_df', iterative_pu_gen_cost),\n",
    "    ('optload_df', iterative_opt_load),\n",
    "    ('clusterbills_df', iterative_cluster_bills),\n",
    "    ('marketpower_df', iterative_market_power),\n",
    "    ('batterydispatch_df', iterative_battery_dispatch)\n",
    "]\n",
    "\n",
    "dataframes = {}\n",
    "for df_name, data in datasets:\n",
    "    df = pd.DataFrame(index=range(number_of_iterations * len(data[0])), columns=pd.DataFrame(data[0]).columns)\n",
    "    df['iteration'] = None\n",
    "    dataframes[df_name] = df\n",
    "\n",
    "\n",
    "for n in range(number_of_iterations):\n",
    "    for df_name, data in datasets:\n",
    "        print('Output saved succecfully for:'+df_name)\n",
    "        df = dataframes[df_name]\n",
    "        df.iloc[len(data[0]) * n:(n + 1) * len(data[0]), 0:-1] = data[0]\n",
    "        df['iteration'][len(data[0]) * n:(n + 1) * len(data[0])] = n\n",
    "        df.to_csv(output_folder_path +\"/\"+df_name + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380580b6",
   "metadata": {},
   "source": [
    "## Output charts and interactive graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38262114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'number_of_iterations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m total_cluster_bills \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(number_of_iterations)\n\u001b[0;32m      2\u001b[0m total_gen_cost \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(number_of_iterations)\n\u001b[0;32m      3\u001b[0m change_in_bills \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(number_of_iterations)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'number_of_iterations' is not defined"
     ]
    }
   ],
   "source": [
    "total_cluster_bills = np.zeros(number_of_iterations)\n",
    "total_gen_cost = np.zeros(number_of_iterations)\n",
    "change_in_bills = np.zeros(number_of_iterations)\n",
    "change_in_gen_cost =np.zeros(number_of_iterations)\n",
    "change_in_net_profit = np.zeros(number_of_iterations)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(number_of_iterations):\n",
    "    total_cluster_bills[i] = iterative_cluster_bills[i].sum().sum()\n",
    "    total_gen_cost[i] = iterative_total_gen_cost[i]\n",
    "    change_in_bills[i] = total_cluster_bills[i] - total_cluster_bills[0]\n",
    "    change_in_gen_cost[i] =total_gen_cost[0] - total_gen_cost[i]\n",
    "    change_in_net_profit[i] = change_in_gen_cost[i] + change_in_bills[i]\n",
    "\n",
    "\n",
    "\n",
    "fig, (ax1, ax2,ax3) = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "ax1.plot(total_gen_cost/1000000000, color='green')\n",
    "ax1.set_title('Generation Cost')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Billion INR')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(total_cluster_bills/1000000000, color='grey')\n",
    "ax2.set_title('Total DF cluster bills')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Billion INR')\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.bar(range(number_of_iterations), change_in_net_profit/1000000000, width =0.4)\n",
    "ax3.set_title('Change in Net Profit (Savings in Generation Cost - DF Incentives)')\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('Billion INR')\n",
    "ax3.grid(True)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e021bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f19aebcaae74a6f99c8ee98f7b41442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Iteration:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Load shift in different categories of load\n",
    "\n",
    "@interact(iteration=widgets.Dropdown(options=range(number_of_iterations), description='Iteration:'))\n",
    "def update_plot(iteration):\n",
    "    \n",
    "    fig = sp.make_subplots(rows=3, cols=1,shared_xaxes=True,horizontal_spacing=0.05,vertical_spacing=0.05,subplot_titles = ('Base and optimal demand','RE generation forecast','Base and optimal net demand'))\n",
    "    x_values = np.linspace(1, 8760, 8760)\n",
    "    x1 = x_values        \n",
    "        \n",
    "    demand_base = iterative_demand[0]\n",
    "    demand = iterative_demand[iteration]\n",
    "    net_demand_base = iterative_demand[0] - re.sum(axis=1)\n",
    "    net_demand = iterative_demand[iteration] -re.sum(axis=1)\n",
    "    solar_gen = re['Solar']\n",
    "    wind_gen = re['Wind']\n",
    "    \n",
    "    \n",
    "    # Plot the data\n",
    "    fig.add_trace(go.Scatter(x=x1, y=demand_base, mode='lines', name=f'Base demand'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x1, y=demand, mode='lines', name=f'Demand - iteration: {iteration}'), row=1, col=1)\n",
    "          \n",
    "    fig.add_trace(go.Scatter(x=x1, y=solar_gen, mode='lines', name=f'Solar generation'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x1, y=wind_gen, mode='lines', name=f'Wind generation'), row=2, col=1)\n",
    "    \n",
    "   \n",
    "    fig.add_trace(go.Scatter(x=x1, y=net_demand_base, mode='lines', name=f'Base net demand'), row=3, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x1, y=net_demand, mode='lines', name=f'net demand -iteration: {iteration}'), row=3, col=1)\n",
    "   \n",
    "\n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        width=900,\n",
    "        margin=dict(l=2, r=2, b=0, t=100),\n",
    "        boxgroupgap=0.00,\n",
    "       \n",
    "        \n",
    "     )\n",
    "\n",
    "    # Add axis titles for each subplot\n",
    "    fig.update_xaxes(title_text=\"Time (hours)\", row=1, col=1)\n",
    "    fig.update_yaxes(range=[min(demand_base),max(demand_base)],title_text=\"Demand (MW)\", row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Time (hours)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Generation (MW)\", row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Time (hours)\", row=3, col=1)\n",
    "    fig.update_yaxes(range=[min(net_demand_base),max(net_demand_base)],title_text=\"Net Demand (MW)\", row=3, col=1)\n",
    "    \n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df4d41b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b910d04ca4b4a06ae1be98724badfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Iteration:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(iteration=widgets.Dropdown(options=range(number_of_iterations), description='Iteration:'))\n",
    "def update_plot2(iteration):\n",
    "    x_values = np.linspace(1, 8760, 8760)\n",
    "    x1 = x_values \n",
    "    fig = sp.make_subplots(rows=3, cols=1,shared_xaxes=True,horizontal_spacing=0.05,vertical_spacing=0.05,subplot_titles = ('Tariff signal','Per Unit Generation cost','Flexibility offered by consumers'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x1, y=iterative_tariff_signals[0].iloc[:,0], mode='lines',  line=dict(shape='hv'), name=f'Base tariff signal'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x1, y=iterative_tariff_signals[iteration].iloc[:,1], mode='lines', line=dict(shape='hv'), name=f'Tariff signal - iteration: {iteration}'), row=1, col=1)\n",
    "          \n",
    "    fig.add_trace(go.Scatter(x=x1, y=iterative_pu_gen_cost[0], mode='lines',line=dict(shape='hv'), name=f'Pu gen cost base'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x1, y=iterative_pu_gen_cost[iteration], mode='lines', line=dict(shape='hv'),name=f'Pu gen cost iteration: {iteration}'), row=2, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=x1, y=-iterative_opt_load[0].iloc[:,:].sum(axis=1)+iterative_opt_load[iteration].iloc[:,:].sum(axis=1), mode='lines',line=dict(shape='hv'), name=f'Flexibility offered in iteration {iteration}'), row=3, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        width=900,\n",
    "        margin=dict(l=3, r=2, b=0, t=100),\n",
    "        boxgroupgap=0.00,\n",
    "       \n",
    "        \n",
    "     )\n",
    "\n",
    "    # Add axis titles for each subplot\n",
    "    fig.update_xaxes(title_text=\"Time (hours)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"INR/kWh\", row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Time (hours)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"INR/kWh\", row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Time (hours)\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"MW\", row=3, col=1)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e56b87b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c998188589844431bf9a1c2d3c3960b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Iteration:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(iteration=widgets.Dropdown(options=range(number_of_iterations), description='Iteration:'))\n",
    "def update_plot5(iteration):\n",
    "    \n",
    "    fig = sp.make_subplots(rows=3, cols=1,shared_xaxes=True,horizontal_spacing=0.05,vertical_spacing=0.05,subplot_titles = ('Market drawl','Battery state of charge','Generation shcedule from generators'))\n",
    "    x1 = np.linspace(1, 8760, 8760)\n",
    "          \n",
    "        \n",
    "#     battery_soc = \n",
    "#     market_power = iterative_market_power[iteration]\n",
    "#     conventional_gen_sch = iterative_demand[iteration] - battery_soc - market_power\n",
    "\n",
    "    \n",
    "    \n",
    "    # Plot the data\n",
    "    fig.add_trace(go.Scatter(x=x1, y=iterative_demand[0], mode='lines', name=f'Base battery soc'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x1, y=iterative_market_power[1][0], mode='lines', name=f'Battery soc - iteration: {iteration}'), row=1, col=1)\n",
    "          \n",
    "#     fig.add_trace(go.Scatter(x=x1, y=iterative_market_power[0], mode='lines', name=f'Solar generation'), row=2, col=1)\n",
    "#     fig.add_trace(go.Scatter(x=x1, y=iterative_market_power[iteration], mode='lines', name=f'Wind generation'), row=1, col=1)\n",
    "#     \n",
    "   \n",
    "#     fig.add_trace(go.Scatter(x=x1, y=iterative_demand[0] -iterative_battery_dispatch[0] -iterative_market_power[0], mode='lines', name=f'Base conventional generator schedule'), row=3, col=1)\n",
    "#     fig.add_trace(go.Scatter(x=x1, y=conventional_gen_sch, mode='lines', name=f'Convnetional generator schedule -iteration: {iteration}'), row=3, col=1)\n",
    "   \n",
    "\n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        width=900,\n",
    "        margin=dict(l=2, r=2, b=0, t=100),\n",
    "        boxgroupgap=0.00,\n",
    "       \n",
    "        \n",
    "     )\n",
    "\n",
    "    # Add axis titles for each subplot\n",
    "#     fig.update_xaxes(title_text=\"Time (hours)\", row=1, col=1)\n",
    "#     fig.update_yaxes(range=[min(demand_base),max(demand_base)],title_text=\"Demand (MW)\", row=1, col=1)\n",
    "    \n",
    "#     fig.update_xaxes(title_text=\"Time (hours)\", row=2, col=1)\n",
    "#     fig.update_yaxes(title_text=\"Generation (MW)\", row=2, col=1)\n",
    "    \n",
    "#     fig.update_xaxes(title_text=\"Time (hours)\", row=3, col=1)\n",
    "#     fig.update_yaxes(range=[min(net_demand_base),max(net_demand_base)],title_text=\"Net Demand (MW)\", row=3, col=1)\n",
    "    \n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8c9bbf33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139dcfd1b3bf4f15ac52c6efca618c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='cluster:', options=('hos_Cluster-1', 'hos_Cluster-2', 'hos_Cluster…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(clusters=widgets.Dropdown(options=iterative_opt_load[0].columns, description='cluster:'))\n",
    "\n",
    "\n",
    "def update_plot3(clusters):\n",
    "    x_values = np.linspace(1, 8760, 8760)\n",
    "    x1 = x_values \n",
    "    fig = sp.make_subplots(rows=1, cols=1,shared_xaxes=True,subplot_titles = clusters)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(number_of_iterations):\n",
    "        selected_df = iterative_opt_load[i]\n",
    "      \n",
    "        fig.add_trace(go.Scatter(x=x1, y=selected_df.loc[:,clusters], mode='lines', line=dict(shape='hv'), name=f'Cluster load: iteration {i}'), row=1, col=1)\n",
    "    \n",
    "          \n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        width=900,\n",
    "        boxgroupgap=0.00,   \n",
    "        \n",
    "     )\n",
    "\n",
    "    # Add axis titles for each subplot\n",
    "    fig.update_xaxes(title_text=\"Time (hours)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"MW\", row=1, col=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2fc29f34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012402a6cbeb48edaf1dbd6396ffb608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Iteration:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(iteration=widgets.Dropdown(options=range(number_of_iterations), description='Iteration:'))\n",
    "def update_plot4(iteration):\n",
    "    x_values = np.linspace(1, 8760, 8760)\n",
    "    x1 = x_values \n",
    "#     gencdc = iterative_demand[0].sort_values().reset_index()\n",
    "    gencdc = iterative_pu_gen_cost[0].sort_values().reset_index()\n",
    "    gencdc_i = iterative_pu_gen_cost[iteration].sort_values().reset_index()\n",
    "    gen_cost_dc = gencdc.iloc[:,1]\n",
    "#     gencdc = iterative_demand[iteration].sort_values().reset_index()\n",
    "    gen_cost_dc_i = gencdc_i.iloc[:,1]\n",
    "    fig = sp.make_subplots(rows=1, cols=1,shared_xaxes=True,subplot_titles ='Load duration curve')\n",
    "    fig.add_trace(go.Scatter(x=x1, y=gen_cost_dc, mode='lines', name=f'Load duration curve base'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x1, y=gen_cost_dc_i, mode='lines', name=f'Load duration curve iteration: {iteration}'), row=1, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        width=900,   \n",
    "        \n",
    "     )\n",
    "\n",
    "    # Add axis titles for each subplot\n",
    "    fig.update_xaxes(title_text=\"Time (hours)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"MW\", row=1, col=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    fig.show()             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
